{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Pricing using Bandits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The demand curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assumptions**: I am the only one selling this item (monopoly), I have infinite availability, and $n_t$ customers show up at day $t$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "price = 15\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "\n",
    "sold = np.random.binomial(1, conversion_probability(price))\n",
    "\n",
    "print(f'Probability of purchase at price {price}: {conversion_probability(price)}')\n",
    "\n",
    "# will the customer buy my product at this price?\n",
    "print(f'Sold? {bool(sold)}')"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "n_customers = 100\n",
    "\n",
    "sales = np.random.binomial(n_customers, conversion_probability(price))\n",
    "\n",
    "# will the customer buy my product at this price?\n",
    "print(f'How many sales? {sales}')"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation over multiple customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "prices = np.linspace(10, 20, 100)\n",
    "n_customers = 100\n",
    "\n",
    "expected_demand_curve = n_customers*conversion_probability(prices)\n",
    "\n",
    "estimated_demand_curve = np.random.binomial(n_customers, conversion_probability(prices))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prices, expected_demand_curve, label='Expected Demand Curve')\n",
    "plt.plot(prices, estimated_demand_curve, label='Estimated Demand Curve')\n",
    "plt.xlabel('Item Price')\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I compute my profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "cost = 10\n",
    "\n",
    "expected_profit_curve = n_customers*conversion_probability(prices)*(prices-cost)\n",
    "\n",
    "estimated_profit_curve = np.random.binomial(n_customers, conversion_probability(prices))*(prices-cost)\n",
    "\n",
    "best_price_index = np.argmax(expected_profit_curve)\n",
    "best_price = prices[best_price_index]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prices, expected_profit_curve, label='Expected Profit Curve')\n",
    "plt.plot(prices, estimated_profit_curve, label='Estimated Profit Curve')\n",
    "plt.scatter(best_price, expected_profit_curve[best_price_index], color='red', s=50)\n",
    "plt.xlabel('Item Price')\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can I find the better price, while maximizing my cumulative profits? -> Exploration-Exploitation trade-off -> Online Learning!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's formalize the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "class PricingEnvironment:\n",
    "    def __init__(self, conversion_probability, cost):\n",
    "        self.conversion_probability = conversion_probability\n",
    "        self.cost = cost\n",
    "\n",
    "    def round(self, p_t, n_t):\n",
    "        d_t = np.random.binomial(n_t, self.conversion_probability(p_t))\n",
    "        r_t = (p_t - self.cost)*d_t\n",
    "        return d_t, r_t\n",
    "    \n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "env = PricingEnvironment(conversion_probability=conversion_probability, cost=5)\n",
    "env.round(10, 100)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: this is the number of sales, not the profit!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: try to modify the environment to allow for seed fixing, in order to make the simulations entirely reproducible, i.e., generate all the rewards sequences a priori"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Approach: Discretization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea: I partition possible prices in a discrete number, then use a standard MAB algorithm such as UCB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "class UCB1Agent:\n",
    "    def __init__(self, K, T, range=1):\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.range = range\n",
    "        self.a_t = None\n",
    "        self.average_rewards = np.zeros(K)\n",
    "        self.N_pulls = np.zeros(K)\n",
    "        self.t = 0\n",
    "    \n",
    "    def pull_arm(self):\n",
    "        if self.t < self.K:\n",
    "            self.a_t = self.t \n",
    "        else:\n",
    "            ucbs = self.average_rewards + self.range*np.sqrt(2*np.log(self.T)/self.N_pulls)\n",
    "            self.a_t = np.argmax(ucbs)\n",
    "        return self.a_t\n",
    "    \n",
    "    def update(self, r_t):\n",
    "        self.N_pulls[self.a_t] += 1\n",
    "        self.average_rewards[self.a_t] += (r_t - self.average_rewards[self.a_t])/self.N_pulls[self.a_t]\n",
    "        self.t += 1"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I use a standard MAB agent with a **very** large number of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "T = 10000 # try T=100, why this behavior?\n",
    "K = 100\n",
    "\n",
    "prices = np.linspace(10,20,K) # 100 actions!\n",
    "cost = 10\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "\n",
    "n_customers = 100 # I assume the number of customers arriving is the same everyday (for now, in general this is not true)\n",
    "\n",
    "reward_function = lambda price, n_sales: (price-cost)*n_sales\n",
    "maximum_profit = reward_function(max(prices), n_customers) # the maximum possible reward is selling at the maximum price to every possible customer\n",
    "\n",
    "# let's compute the clairvoyant\n",
    "profit_curve = reward_function(prices, n_customers*conversion_probability(prices))\n",
    "best_price_index = np.argmax(profit_curve)\n",
    "best_price = prices[best_price_index]\n",
    "expected_clairvoyant_rewards = np.repeat(profit_curve[best_price_index], T)\n",
    "\n",
    "n_trials = 100\n",
    "\n",
    "regret_per_trial = []\n",
    "\n",
    "for seed in range(n_trials):\n",
    "    np.random.seed(seed)\n",
    "    env = PricingEnvironment(conversion_probability=conversion_probability, cost=cost)\n",
    "    ucb_agent = UCB1Agent(K, T, range=maximum_profit)\n",
    "\n",
    "    agent_rewards = np.array([])\n",
    "\n",
    "    for t in range(T):\n",
    "        pi_t = ucb_agent.pull_arm() ## the agent returns the index!!\n",
    "        p_t = prices[pi_t] # I get the actual price\n",
    "        d_t, r_t = env.round(p_t, n_customers)\n",
    "        ucb_agent.update(r_t)\n",
    "\n",
    "        agent_rewards = np.append(agent_rewards, r_t)\n",
    "\n",
    "    cumulative_regret = np.cumsum(expected_clairvoyant_rewards-agent_rewards)\n",
    "    regret_per_trial.append(cumulative_regret)\n",
    "\n",
    "regret_per_trial = np.array(regret_per_trial)\n",
    "\n",
    "average_regret = regret_per_trial.mean(axis=0)\n",
    "regret_sd = regret_per_trial.std(axis=0)\n",
    "\n",
    "plt.plot(np.arange(T), average_regret, label='Average Regret')\n",
    "plt.title('cumulative regret of UCB1')\n",
    "plt.fill_between(np.arange(T),\n",
    "                average_regret-regret_sd/np.sqrt(n_trials),\n",
    "                average_regret+regret_sd/np.sqrt(n_trials),\n",
    "                alpha=0.3,\n",
    "                label='Uncertainty')\n",
    "#plt.plot((0,T-1), (average_regret[0], average_regret[-1]), 'ro', linestyle=\"--\")\n",
    "plt.xlabel('$t$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(np.arange(100), ucb_agent.N_pulls)\n",
    "plt.axhline(best_price_index, color='red', label='Best price')\n",
    "plt.ylabel('actions')\n",
    "plt.xlabel('numer of pulls')\n",
    "plt.legend()\n",
    "plt.title('Number of pulls for each action')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This approach is often too naive, since the regret of MAB algorithms scales with $\\sqrt{K}$!\n",
    "\n",
    "$$ R_T \\le \\sqrt{KT \\log(T)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandits with Arm Structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic pricing is an example of bandit problem with additional structure. \n",
    "\n",
    "### In standard Multi-Armed Bandits, actions are assumed to be independent, and there is no structure among them. In pricing applications, it is customary to assume that similar prices will lead to similar outcomes, thus there is some sort of \"smoothness\" in the reward function. Moreover, actions naturally belong to an infinite set (even though prices can be discretized to the cent, such a large number can be considered infinite)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Processes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Processes model a set of observations as multivariate normals.\n",
    "\n",
    "### They rely on a _kernel_, that is an operator that quantifies the covariance between two samples. Using this covariance notion, we are able to estimate uncertainty simultaneously an all points. We will focus on one of the most common kernels: Radial Basis Function Kernel (RBF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "class RBFGaussianProcess:\n",
    "    def __init__(self, scale=1, reg=1e-2):\n",
    "        self.scale = scale \n",
    "        self.reg = reg\n",
    "        self.k_xx_inv = None\n",
    "\n",
    "    def rbf_kernel_incr_inv(self, B, C, D):\n",
    "        temp = np.linalg.inv(D - C @ self.k_xx_inv @ B)\n",
    "        block1 = self.k_xx_inv + self.k_xx_inv @ B @ temp @ C @ self.k_xx_inv\n",
    "        block2 = - self.k_xx_inv @ B @ temp\n",
    "        block3 = - temp @ C @ self.k_xx_inv\n",
    "        block4 = temp\n",
    "        res1 = np.concatenate((block1, block2), axis=1)\n",
    "        res2 = np.concatenate((block3, block4), axis=1)\n",
    "        res = np.concatenate((res1, res2), axis=0)\n",
    "        return res\n",
    "\n",
    "    def rbf_kernel(self, a, b):\n",
    "        a_ = a.reshape(-1, 1)\n",
    "        b_ = b.reshape(-1, 1)\n",
    "        output = -1 * np.ones((a_.shape[0], b_.shape[0]))\n",
    "        for i in range(a_.shape[0]):\n",
    "            output[i, :] = np.power(a_[i] - b_, 2).ravel()\n",
    "        return np.exp(-self.scale * output)\n",
    "    \n",
    "    def fit(self, x=np.array([]), y=np.array([])):\n",
    "        x,y = np.array(x),np.array(y)\n",
    "        if self.k_xx_inv is None:\n",
    "            self.y = y.reshape(-1,1)\n",
    "            self.x = x.reshape(-1,1)\n",
    "            k_xx = self.rbf_kernel(self.x, self.x) + self.reg * np.eye(self.x.shape[0])\n",
    "            self.k_xx_inv = np.linalg.inv(k_xx)\n",
    "        else:\n",
    "            B = self.rbf_kernel(self.x, x)\n",
    "            self.x = np.vstack((self.x, x))\n",
    "            self.y = np.vstack((self.y, y))\n",
    "            self.k_xx_inv = self.rbf_kernel_incr_inv(B, B.T, np.array([1 + self.reg]))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_predict):\n",
    "        k = self.rbf_kernel(x_predict, self.x)\n",
    "\n",
    "        mu_hat = k @ self.k_xx_inv @ self.y\n",
    "        sigma_hat = 1 - np.diag(k @ self.k_xx_inv @ k.T)\n",
    "\n",
    "        return mu_hat.ravel(), sigma_hat.ravel()"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a reference on Gaussian Processes and Bandits see https://arxiv.org/pdf/1704.00445.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a set of (price, sales) observations, how can I use GPs to model the demand curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "price_range = np.linspace(10,20,1000)\n",
    "price_samples = 10 + 10 * np.random.sample(size=10).round(2) # randomly generating prices\n",
    "\n",
    "# GP works well if the samples are in [0,1], thus we normalize them\n",
    "normalized_sales_samples = np.random.binomial(n_customers, conversion_probability(price_samples))/n_customers\n",
    "\n",
    "# Instantiate a Gaussian Process model, the scale is usually set of an order of magnitude below the order of magnitude of the range \n",
    "# prices in the range (10,20) -> scale in the range (1,10)\n",
    "gp = RBFGaussianProcess(scale=1)\n",
    "\n",
    "gp.fit(price_samples, normalized_sales_samples)\n",
    "\n",
    "mu, sigma = gp.predict(price_range)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(price_samples, normalized_sales_samples, color='C1')\n",
    "plt.plot(price_range, mu)\n",
    "plt.fill_between(price_range, mu-sigma, mu+sigma, alpha=0.3)\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "price_samples, normalized_sales_samples =  np.array([]), np.array([])\n",
    "cost = 10\n",
    "\n",
    "gp = RBFGaussianProcess(scale=1).fit()\n",
    "mu, sigma = gp.predict(price_range)\n",
    "profit_mu, profit_sigma = mu*(price_range-cost), sigma*(price_range-cost)\n",
    "\n",
    "f,ax = plt.subplots(1,2, figsize=(20,10))\n",
    "ax[0].plot(price_range, mu)\n",
    "ax[0].fill_between(price_range, mu-sigma, mu+sigma, alpha=0.3)\n",
    "ax[0].set_title('Estimated Demand - 0 samples (prior)')\n",
    "ax[1].plot(price_range, profit_mu, color='C1')\n",
    "ax[1].fill_between(price_range, profit_mu-profit_sigma, profit_mu+profit_sigma, alpha=0.3, color='C1')\n",
    "ax[1].set_title('Estimated Profit - 0 samples (prior)')\n",
    "plt.show();\n",
    "\n",
    "for _ in range(10):\n",
    "    p = np.random.sample()*10 + 10\n",
    "    s = np.random.binomial(n_customers, conversion_probability(p))/n_customers\n",
    "\n",
    "    price_samples = np.append(price_samples, p)\n",
    "    normalized_sales_samples = np.append(normalized_sales_samples, s)\n",
    "\n",
    "    gp.fit(p, s)\n",
    "\n",
    "    mu, sigma = gp.predict(price_range)\n",
    "    profit_mu, profit_sigma = mu*(price_range-cost), sigma*(price_range-cost)\n",
    "\n",
    "    f,ax = plt.subplots(1,2, figsize=(20,10))\n",
    "    ax[0].plot(price_range, mu)\n",
    "    ax[0].fill_between(price_range, mu-sigma, mu+sigma, alpha=0.3)\n",
    "    ax[0].set_title(f'Estimated Demand - {_+1} samples (prior)')\n",
    "    ax[0].scatter(price_samples, normalized_sales_samples)\n",
    "    ax[1].plot(price_range, profit_mu, color='C1')\n",
    "    ax[1].fill_between(price_range, profit_mu-profit_sigma, profit_mu+profit_sigma, alpha=0.3, color='C1')\n",
    "    ax[1].set_title(f'Estimated Profit - {_+1} samples (prior)')\n",
    "    ax[1].scatter(price_samples, normalized_sales_samples*(price_samples-cost))\n",
    "    plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea: why don't we choose the price having the large potential profit? -> GP-UCB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GP-UCB Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP-UCB uses the Optimism principle just like UCB1. However, UCB1 doesn't consider how rewards from different actions may be related, while GP-UCB does so. The upper confidence bound is computed by summing the average of the GP estimation plus a term which accounts for the estimation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "# From the agent's point of view, action set is [0,1]. If the actual actions are outside this\n",
    "# set, we can always perform a rescaling outside the class.\n",
    "class GPUCBAgent:\n",
    "    def __init__(self, T, discretization=100):\n",
    "        self.T = T\n",
    "        self.arms = np.linspace(0, 1, discretization)\n",
    "        self.gp = RBFGaussianProcess(scale=2).fit()\n",
    "        self.a_t = None\n",
    "        self.action_hist = np.array([])\n",
    "        self.reward_hist = np.array([])\n",
    "        self.mu_t = np.zeros(discretization)\n",
    "        self.sigma_t = np.zeros(discretization)\n",
    "        self.gamma = lambda t: np.log(t+1)**2 \n",
    "        self.beta = lambda t: 1 + 0.5*np.sqrt(2 * (self.gamma(t) + 1 + np.log(T)))\n",
    "        self.N_pulls = np.zeros(discretization)\n",
    "        self.t = 0\n",
    "    \n",
    "    def pull_arm(self):\n",
    "        self.mu_t, self.sigma_t = self.gp.predict(self.arms) \n",
    "        ucbs = self.mu_t + self.beta(t) * self.sigma_t\n",
    "        self.a_t = np.argmax(ucbs)\n",
    "        return self.arms[self.a_t]\n",
    "    \n",
    "    def update(self, r_t):\n",
    "        self.N_pulls[self.a_t] += 1\n",
    "        self.action_hist = np.append(self.action_hist, self.arms[self.a_t])\n",
    "        self.reward_hist = np.append(self.reward_hist, r_t)\n",
    "        self.gp = self.gp.fit(self.arms[self.a_t], r_t)\n",
    "        self.t += 1"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $UCB_t(a) = \\mu_{t-1}(a) + \\beta_t\\sigma_{t-1}(a)$, for $ a\\in [0,1]$ (continuous action set).\n",
    "\n",
    "### $\\beta_t$ is the parameter governing exploration. It accounts for two main factors: $\\gamma_t$, which represents the maximum information that can be gained at round $t$, and a term in the order of $\\mathcal{O}(\\sqrt{\\log(T)})$ that incentivizes exploration (in a similar way as UCB1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "def rescale(x, min_x, max_x):\n",
    "    return min_x + (max_x-min_x)*x\n",
    "\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "reward_function = lambda price, n_sales: (price-cost)*n_sales\n",
    "maximum_profit = reward_function(max(prices), n_customers) # the maximum possible reward is selling at the maximum price to every possible customer\n",
    "\n",
    "T = 500\n",
    "min_price, max_price = 10, 20\n",
    "n_customers = 100\n",
    "cost = 10\n",
    "agent = GPUCBAgent(T)\n",
    "np.random.seed(2)\n",
    "env = PricingEnvironment(conversion_probability=conversion_probability, cost=cost)\n",
    "\n",
    "# let's compute the clairvoyant\n",
    "prices = np.linspace(min_price, max_price, 1000)\n",
    "profit_curve = reward_function(prices, n_customers*conversion_probability(prices))\n",
    "best_price_index = np.argmax(profit_curve)\n",
    "best_price = prices[best_price_index]\n",
    "expected_clairvoyant_rewards = np.repeat(profit_curve[best_price_index], T)\n",
    "\n",
    "agent_rewards = np.array([])\n",
    "for t in range(T):\n",
    "    p_t = agent.pull_arm()\n",
    "    p_t = rescale(p_t, min_price, max_price)\n",
    "    d_t, r_t = env.round(p_t, n_t=n_customers)\n",
    "    agent.update(r_t/n_customers)\n",
    "    agent_rewards = np.append(agent_rewards, r_t)\n",
    "\n",
    "cumulative_regret = np.cumsum(expected_clairvoyant_rewards-agent_rewards)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main drawback of this strategy: computational burden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "source": [
    "prices = rescale(agent.action_hist, min_price, max_price)\n",
    "profits = agent.reward_hist"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "source": [
    "gp = RBFGaussianProcess(scale=2)\n",
    "gp.fit(prices, profits)\n",
    "mu, sigma = gp.predict(np.linspace(10,20,100))\n",
    "plt.scatter(prices, profits, label='Samples', color='C1')\n",
    "plt.plot(np.linspace(10,20,100), mu, label='Average Normalized Profit')\n",
    "plt.axvline(best_price, color='red',label='Optimal Price')\n",
    "plt.fill_between(np.linspace(10,20,100), mu-sigma, mu+sigma, alpha=0.3, label='Uncertainty', color='C0')\n",
    "plt.title('GPUCB - Final estimated profit curve (normalized)')\n",
    "plt.xlabel('Price')\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How's the cumulative regret?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.plot(cumulative_regret)\n",
    "plt.title('Cumulative Regret of GP-UCB')\n",
    "plt.xlabel('$t$')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another drawback: instability! Mainly due to Gaussian Processes tendency to overfit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm seems to perform better than a UCB1 strategy with price discretization, but we need a more reliable estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "source": [
    "def rescale(x, min_x, max_x):\n",
    "    return min_x + (max_x-min_x)*x\n",
    "\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "reward_function = lambda price, n_sales: (price-cost)*n_sales\n",
    "maximum_profit = reward_function(max(prices), n_customers) # the maximum possible reward is selling at the maximum price to every possible customer\n",
    "\n",
    "T = 200\n",
    "K = 100 # arbitrary discretization\n",
    "\n",
    "min_price, max_price = 10, 20\n",
    "n_customers = 100\n",
    "cost = 10\n",
    "\n",
    "# let's compute the clairvoyant\n",
    "prices = np.linspace(min_price, max_price, K)\n",
    "profit_curve = reward_function(prices, n_customers*conversion_probability(prices))\n",
    "best_price_index = np.argmax(profit_curve)\n",
    "best_price = prices[best_price_index]\n",
    "expected_clairvoyant_rewards = np.repeat(profit_curve[best_price_index], T)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "gp_all_cumulative_regrets = []\n",
    "ucb_all_cumulative_regrets = []\n",
    "for i in range(n_epochs):\n",
    "    gp_agent = GPUCBAgent(T)\n",
    "    ucb1_agent = UCB1Agent(K, T, range=maximum_profit)\n",
    "\n",
    "    np.random.seed(10*i)\n",
    "    env = PricingEnvironment(conversion_probability=conversion_probability, cost=cost)\n",
    "\n",
    "    gp_agent_rewards = np.array([])\n",
    "    ucb_agent_rewards = np.array([])\n",
    "    for t in range(T):\n",
    "        p_t = gp_agent.pull_arm()\n",
    "        p_t = rescale(p_t, min_price, max_price)\n",
    "        d_t, r_t = env.round(p_t, n_t=n_customers)\n",
    "        gp_agent.update(r_t/n_customers)\n",
    "        gp_agent_rewards = np.append(gp_agent_rewards, r_t)\n",
    "\n",
    "        p_t = ucb1_agent.pull_arm()\n",
    "        p_t = prices[p_t]\n",
    "        d_t, r_t = env.round(p_t, n_t=n_customers)\n",
    "        ucb1_agent.update(r_t)\n",
    "        ucb_agent_rewards = np.append(ucb_agent_rewards, r_t)\n",
    "\n",
    "    gp_all_cumulative_regrets.append(np.cumsum(expected_clairvoyant_rewards-gp_agent_rewards))\n",
    "\n",
    "    ucb_all_cumulative_regrets.append(np.cumsum(expected_clairvoyant_rewards-ucb_agent_rewards))\n",
    "\n",
    "gp_all_cumulative_regrets = np.array(gp_all_cumulative_regrets)\n",
    "ucb_all_cumulative_regrets = np.array(ucb_all_cumulative_regrets)\n",
    "\n",
    "gp_average_cumulative_regret = gp_all_cumulative_regrets.mean(axis=0)\n",
    "gp_cumulative_regret_std = gp_all_cumulative_regrets.std(axis=0)\n",
    "\n",
    "ucb_average_cumulative_regret = ucb_all_cumulative_regrets.mean(axis=0)\n",
    "ucb_cumulative_regret_std = ucb_all_cumulative_regrets.std(axis=0)\n",
    "\n",
    "plt.plot(np.arange(T), gp_average_cumulative_regret, label='GP Average Regret')\n",
    "plt.fill_between(np.arange(T),\n",
    "                gp_average_cumulative_regret-gp_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                gp_average_cumulative_regret+gp_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                alpha=0.3)\n",
    "plt.plot(np.arange(T), ucb_average_cumulative_regret, label='UCB1 Average Regret')\n",
    "plt.fill_between(np.arange(T),\n",
    "                ucb_average_cumulative_regret-ucb_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                ucb_average_cumulative_regret+ucb_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The performance gap is clear. Why the weird behavior of UCB1's average cumulative regret?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: with $T=200$, UCB1 has to spend half of its time just to try all arms once!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What would be the discretization prescribed by theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "epsilon = T**(-0.33)\n",
    "K = int(1/epsilon)\n",
    "K"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "source": [
    "def rescale(x, min_x, max_x):\n",
    "    return min_x + (max_x-min_x)*x\n",
    "\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "reward_function = lambda price, n_sales: (price-cost)*n_sales\n",
    "maximum_profit = reward_function(max(prices), n_customers) # the maximum possible reward is selling at the maximum price to every possible customer\n",
    "\n",
    "T = 200\n",
    "\n",
    "min_price, max_price = 10, 20\n",
    "n_customers = 100\n",
    "cost = 10\n",
    "\n",
    "# let's compute the clairvoyant\n",
    "prices = np.linspace(min_price, max_price, K)\n",
    "profit_curve = reward_function(prices, n_customers*conversion_probability(prices))\n",
    "best_price_index = np.argmax(profit_curve)\n",
    "best_price = prices[best_price_index]\n",
    "expected_clairvoyant_rewards = np.repeat(profit_curve[best_price_index], T)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "gp_all_cumulative_regrets = []\n",
    "ucb_all_cumulative_regrets = []\n",
    "for i in range(n_epochs):\n",
    "    gp_agent = GPUCBAgent(T)\n",
    "    ucb1_agent = UCB1Agent(K, T, range=maximum_profit)\n",
    "\n",
    "    np.random.seed(10*i)\n",
    "    env = PricingEnvironment(conversion_probability=conversion_probability, cost=cost)\n",
    "\n",
    "    gp_agent_rewards = np.array([])\n",
    "    ucb_agent_rewards = np.array([])\n",
    "    for t in range(T):\n",
    "        p_t = gp_agent.pull_arm()\n",
    "        p_t = rescale(p_t, min_price, max_price)\n",
    "        d_t, r_t = env.round(p_t, n_t=n_customers)\n",
    "        gp_agent.update(r_t/n_customers)\n",
    "        gp_agent_rewards = np.append(gp_agent_rewards, r_t)\n",
    "\n",
    "        p_t = ucb1_agent.pull_arm()\n",
    "        p_t = prices[p_t]\n",
    "        d_t, r_t = env.round(p_t, n_t=n_customers)\n",
    "        ucb1_agent.update(r_t)\n",
    "        ucb_agent_rewards = np.append(ucb_agent_rewards, r_t)\n",
    "\n",
    "    gp_all_cumulative_regrets.append(np.cumsum(expected_clairvoyant_rewards-gp_agent_rewards))\n",
    "\n",
    "    ucb_all_cumulative_regrets.append(np.cumsum(expected_clairvoyant_rewards-ucb_agent_rewards))\n",
    "\n",
    "gp_all_cumulative_regrets = np.array(gp_all_cumulative_regrets)\n",
    "ucb_all_cumulative_regrets = np.array(ucb_all_cumulative_regrets)\n",
    "\n",
    "gp_average_cumulative_regret = gp_all_cumulative_regrets.mean(axis=0)\n",
    "gp_cumulative_regret_std = gp_all_cumulative_regrets.std(axis=0)\n",
    "\n",
    "ucb_average_cumulative_regret = ucb_all_cumulative_regrets.mean(axis=0)\n",
    "ucb_cumulative_regret_std = ucb_all_cumulative_regrets.std(axis=0)\n",
    "\n",
    "plt.plot(np.arange(T), gp_average_cumulative_regret, label='GP Average Regret')\n",
    "plt.fill_between(np.arange(T),\n",
    "                gp_average_cumulative_regret-gp_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                gp_average_cumulative_regret+gp_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                alpha=0.3)\n",
    "plt.plot(np.arange(T), ucb_average_cumulative_regret, label='UCB1 Average Regret')\n",
    "plt.fill_between(np.arange(T),\n",
    "                ucb_average_cumulative_regret-ucb_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                ucb_average_cumulative_regret+ucb_cumulative_regret_std/np.sqrt(n_epochs),\n",
    "                alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparable performances, but this time the regret seems to have at least a sub-linear behavior ($\\mathcal{O}(T^\\frac{2}{3}\\log(T))$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regret of GP-UCB:\n",
    "### $$ R_T = \\mathcal{O}(\\sqrt{T}\\gamma_T) =  \\mathcal{O}(\\sqrt{T}\\log(T)^{d+1})$$\n",
    "### where $d$ is the dimension of the action space, in our case $d=1$. Note that the total information gain term scales exponentially with the dimension of the action space -> curse of dimensionality!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-dimensional action spaces ($d>1$) are very important in dynamic pricing, since they model the scenario in which a seller is offering multiple product, with possibly correlated demands. GP-UCB can be extended to the multi-dimensional scenario, see the reference above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
